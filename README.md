# ğŸ›’ Amazon Reviews - Analyse de Sentiments â­

## ğŸ“‹ Description du Projet

Ce projet compare trois approches de machine learning pour prÃ©dire automatiquement la note (1-5 Ã©toiles) d'une review Amazon Ã  partir de son contenu textuel. L'objectif est d'Ã©valuer l'efficacitÃ© du **Transfer Learning** avec les modÃ¨les Transformers par rapport Ã  une approche baseline traditionnelle.

### ğŸ¯ Objectifs
- Analyser les reviews Amazon Fine Food pour comprendre les patterns de sentiment
- ImplÃ©menter et comparer 3 modÃ¨les : Ridge Regression (baseline), BERT, et DistilBERT
- Appliquer des techniques de Transfer Learning sur des modÃ¨les prÃ©-entraÃ®nÃ©s
- DÃ©velopper une application Streamlit interactive pour la prÃ©diction en temps rÃ©el

## ğŸ“Š Dataset

**Source** : [Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews) (Kaggle)

- **Taille** : ~500K reviews
- **PÃ©riode** : Octobre 1999 - Octobre 2012
- **Variables principales** :
  - `Text` : Contenu textuel de la review
  - `Score` : Note de 1 Ã  5 Ã©toiles
- **Preprocessing** : Nettoyage, suppression des stop words, tokenisation

### Justification du choix
- **ComplexitÃ©** : Dataset large avec texte non-structurÃ©
- **DÃ©fi NLP** : Analyse de sentiment multi-classe (rÃ©gression)
- **RÃ©alisme** : Cas d'usage industriel (e-commerce)

## ğŸ—ï¸ Architecture du Projet

```
AmazonReviews-Regression/
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py         # Main Streamlit application
â”‚   â””â”€â”€ test_streamlit.py        # Application tests
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Reviews.csv              # Raw dataset
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 0.2.6.0                  # Version directory
â”‚   â”œâ”€â”€ 1_EDA_cleaning.ipynb     # Exploratory Data Analysis & Cleaning
â”‚   â”œâ”€â”€ 2_Modeling_Training.ipynb # Model Development & Training
â”‚   â”œâ”€â”€ clean_reviews.csv        # Cleaned dataset
â”‚   â”œâ”€â”€ model_comparison.csv     # Model performance comparison
â”‚   â”œâ”€â”€ random_forest_model.pkl  # Trained Random Forest model
â”‚   â”œâ”€â”€ ridge_model.pkl          # Trained Ridge Regression model
â”‚   â”œâ”€â”€ svr_model.pkl           # Trained Support Vector Regression model
â”‚   â””â”€â”€ tfidf_vectorizer.pkl    # TF-IDF vectorizer for text processing
â”œâ”€â”€ .gitattributes              # Git LFS configuration
â”œâ”€â”€ report.docx                 # Project report
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸ¤– ModÃ¨les ImplÃ©mentÃ©s

### 1. ğŸ”¸ Ridge Regression (Baseline)
- **Architecture** : TF-IDF (10K features) + Ridge Regression
- **Justification** : Baseline rapide et interprÃ©table
- **Avantages** : Temps d'entraÃ®nement < 1 min, faible complexitÃ©
- **Performance** : RMSE = 0.9335, MAE = 0.7022

### 2. ğŸ”¹ BERT (Transfer Learning)
- **Architecture** : BERT-base-uncased (110M paramÃ¨tres)
- **MÃ©thode Transfer Learning** :
  - Chargement du modÃ¨le prÃ©-entraÃ®nÃ©
  - Ajout d'une couche de rÃ©gression (`num_labels=1`)
  - Fine-tuning complet avec AdamW optimizer
  - Learning rate scheduling avec warm-up
- **Justification** : Ã‰tat de l'art en NLP, reprÃ©sentations contextuelles bidirectionnelles
- **Performance** : RMSE = 0.8945, MAE = 0.6789

### 3. ğŸ”¹ DistilBERT (Transfer Learning OptimisÃ©)
- **Architecture** : DistilBERT-base-uncased (66M paramÃ¨tres)
- **MÃ©thode Transfer Learning** : Identique Ã  BERT
- **Justification** : 
  - Version "distillÃ©e" de BERT (40% plus petit)
  - Conserve 97% des performances de BERT
  - Meilleur compromis performance/efficacitÃ©
- **Performance** : RMSE = 0.8654, MAE = 0.6532 â­ **Meilleur modÃ¨le**

## ğŸš€ Installation et Utilisation

### PrÃ©requis
```bash
Python 3.8+
CUDA compatible GPU (optionnel, pour accÃ©lÃ©ration)
```

### Installation
```bash
# Cloner le repository
git clone https://github.com/[username]/amazon-reviews-sentiment.git
cd amazon-reviews-sentiment

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Lancement de l'application Streamlit
```bash
cd app
streamlit run streamlit_app.py
```

### EntraÃ®nement des modÃ¨les
```bash
# 1. Analyse exploratoire et nettoyage
jupyter notebook notebooks/EDA_cleaning.ipynb

# 2. EntraÃ®nement des modÃ¨les
jupyter notebook notebooks/Modeling_Training.ipynb
```

## ğŸ“ˆ RÃ©sultats

### Performance des ModÃ¨les

| ModÃ¨le | RMSE (Val) | MAE (Val) | ParamÃ¨tres | Temps Training | ComplexitÃ© |
|--------|------------|-----------|------------|----------------|------------|
| **DistilBERT** â­ | **0.8654** | **0.6532** | 66M | ~10 min | Ã‰levÃ©e |
| BERT | 0.8945 | 0.6789 | 110M | ~15 min | TrÃ¨s Ã‰levÃ©e |
| Ridge (Baseline) | 0.9335 | 0.7022 | 10K | < 1 min | Faible |

### Analyse des RÃ©sultats
- **ğŸ† Meilleur modÃ¨le** : DistilBERT (amÃ©lioration de 7.3% RMSE vs baseline)
- **âš¡ Plus rapide** : Ridge Regression (excellent pour prototypage)
- **ğŸ’¡ Transfer Learning** : AmÃ©lioration significative grÃ¢ce aux reprÃ©sentations prÃ©-entraÃ®nÃ©es

## ğŸ¯ StratÃ©gie de Transfer Learning

### MÃ©thodologie AppliquÃ©e
1. **Feature Extraction** : Utilisation des embeddings prÃ©-entraÃ®nÃ©s
2. **Fine-tuning** : Adaptation des poids pour la tÃ¢che de rÃ©gression
3. **Task-specific Head** : Ajout d'une couche dense pour la prÃ©diction de score
4. **Optimisation** : AdamW avec learning rate scheduling

### Justification des Choix
- **BERT** : RÃ©fÃ©rence en NLP, reprÃ©sentations contextuelles bidirectionnelles
- **DistilBERT** : Version optimisÃ©e, meilleur compromis performance/ressources
- **RÃ©gression** : `problem_type="regression"` avec MSE loss pour prÃ©diction continue

## ğŸ–¥ï¸ Application Streamlit

### FonctionnalitÃ©s
- **ğŸ“Š Exploration des donnÃ©es** : Visualisations interactives, statistiques
- **ğŸ¤– PrÃ©diction en temps rÃ©el** : Test des 3 modÃ¨les sur texte personnalisÃ©
- **ğŸ“ˆ Comparaison des modÃ¨les** : MÃ©triques de performance, analyse
- **ğŸ” Analyse d'erreurs** : Identification des cas difficiles

### Interface
- Navigation par onglets
- Graphiques Plotly interactifs
- PrÃ©dictions comparatives en temps rÃ©el
- Exemples prÃ©-dÃ©finis pour test rapide

## ğŸ“Š Analyse Exploratoire (EDA)

### Insights ClÃ©s
- **Distribution dÃ©sÃ©quilibrÃ©e** : 40% de scores 5/5, 10% de scores 1/5
- **CorrÃ©lation longueur-sentiment** : Reviews positives gÃ©nÃ©ralement plus longues
- **Vocabulaire distinctif** : Mots-clÃ©s spÃ©cifiques par sentiment
- **Patterns temporels** : Ã‰volution des sentiments sur la pÃ©riode

### Visualisations
- Distribution des scores (histogramme + camembert)
- Nuages de mots par sentiment
- Analyse de la longueur des textes
- CorrÃ©lations entre variables

## ğŸ› ï¸ Technologies UtilisÃ©es

### Core ML/NLP
- **PyTorch** : Framework deep learning
- **Transformers (HuggingFace)** : ModÃ¨les prÃ©-entraÃ®nÃ©s BERT/DistilBERT
- **Scikit-learn** : ModÃ¨le baseline, mÃ©triques, preprocessing
- **NLTK** : Traitement du langage naturel

### Visualisation & Interface
- **Streamlit** : Application web interactive
- **Plotly** : Graphiques interactifs
- **Matplotlib/Seaborn** : Visualisations statiques
- **WordCloud** : Nuages de mots

### DÃ©veloppement
- **Pandas/NumPy** : Manipulation de donnÃ©es
- **Jupyter** : DÃ©veloppement interactif
- **tqdm** : Barres de progression

## ğŸ“š MÃ©thodologie

### 1. Preprocessing
```python
# Nettoyage du texte
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+", "", text)  # URLs
    text = re.sub(r"[^a-zA-Z]", " ", text)  # CaractÃ¨res spÃ©ciaux
    text = re.sub(r"\s+", " ", text)  # Espaces multiples
    words = [w for w in text.split() if w not in stop_words]
    return " ".join(words)
```

### 2. Transfer Learning Implementation
```python
# Configuration BERT pour rÃ©gression
model = AutoModelForSequenceClassification.from_pretrained(
    model_name, 
    num_labels=1,  # RÃ©gression
    problem_type="regression"
)

# Fine-tuning avec AdamW
optimizer = AdamW(model.parameters(), lr=2e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, ...)
```

### 3. MÃ©triques d'Ã‰valuation
- **RMSE** : Erreur quadratique moyenne (pÃ©nalise les grandes erreurs)
- **MAE** : Erreur absolue moyenne (interprÃ©table directement)
- **Validation croisÃ©e** : Split train/val/test (60%/20%/20%)

## ğŸ” Analyse d'Erreurs

### Cas Difficiles IdentifiÃ©s
- **Sarcasme** : "Great product... NOT!"
- **Contexte mixte** : Avis positif sur le produit, nÃ©gatif sur la livraison
- **Nuances linguistiques** : Expressions idiomatiques
- **Reviews courtes** : Manque de contexte

## ğŸ™ Remerciements

- **Kaggle** pour le dataset Amazon Fine Food Reviews
- **HuggingFace** pour les modÃ¨les Transformers prÃ©-entraÃ®nÃ©s
- **Streamlit** pour le framework d'application web
- CommunautÃ© open-source pour les outils utilisÃ©s

## ğŸ“ Contact

Pour toute question sur ce projet :
- Email : adammhtazibert@gmail.com
- LinkedIn : https://www.linkedin.com/in/mahamat-azibert-adam
---

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**
